---
title: "Forecasting Cancer Death Rates Across the United States"
author: "Kendall Kikkawa, Jonathan Luo, Andre Sha"
output: pdf_document
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
suppressWarnings(suppressMessages(library(glmnet)))
suppressWarnings(suppressMessages(library(leaps)))
suppressWarnings(suppressMessages(library(DAAG)))
library(knitr)
library(kableExtra)
library(gpairs)
library(grid)
library(lattice)
library(ggplot2)
library(ggpubr)
library(car)
library(usmap)
library(dplyr)
library(tidyr)
library(stringr)
library(reshape2)
library(corrplot)
library(car) #VIF
library(gridExtra)
library(cowplot)
library(forecast)
library(dummies)
library(sjPlot)
library(sjlabelled)
library(sjmisc)
library(lm.beta)
library(maps)
```

```{r, echo=FALSE}
### Data cleaning
cancer <- read.csv("Data/cancer_reg.csv")
fips_codes <- read.csv("Data/FIPS_codes.csv")
state_abbr <- read.csv("Data/State_Abbreviation_Mapping.csv") 
regions <- read.csv("Data/regions.csv")

# Cleaned N/A columns
cancer <- subset(cancer, select=-c(PctSomeCol18_24, PctEmployed16_Over, 
                                   PctPrivateCoverageAlone, binnedInc)) 

# Clean coding error, applied log-transformation of PctBachDeg25_Over after plot inspection. 

cancer[cancer$MedianAge > 100,]$MedianAge = 40.8
cancer[cancer$AvgHouseholdSize < 1,]$AvgHouseholdSize = 1

#Joining Datasets, columns w/ Geographic features. 

County <- sub(",.*$", "", cancer$Geography)
State <- sub("^.*,\\s*", "", cancer$Geography)

empty_subs = c(" County", " Parish", " City and Borough", 
               " Municipality", " Borough", " Census Area")
for (sub_string in empty_subs) {
  County <- sub(sub_string, "", County) 
}

County <- sub("city", "City", County) 
County <- sub("St ", "St. ", County) 

cancer$County<- County
cancer$State <- State
cancer <- subset(cancer, select = -c(Geography)) # Redundant
cancer<- cancer %>% 
  rename(
    state = State
    )

fips_codes$County <- sub("St ", "St. ", fips_codes$County) 
fips <- merge(fips_codes, state_abbr[, c('State', 'Postal.Abbreviation')], 
      by.x='State', by.y='Postal.Abbreviation', all.x=TRUE)
fips <- fips %>% 
  rename(
    State.Abbreviation = State,
    state = State.y
    )
cancer <- left_join(cancer, fips, by=c('County', 'state'))
cancer <- cancer %>% 
  rename(
    fips = FIPS
    )

df <- left_join(cancer, regions, by=c('state'))
df <- subset(df, select = -c(State.Code, State.Abbreviation) )
```

# Introduction

Cancer has a large impact on society, affecting people from all different walks of life across the United States. In this report, we created a regression model that can be used to predict cancer mortality rate for counties across the U.S. Our motivation for pursuing this project stems from a common interest in Healthcare and a curiosity about the types of factors that are related to cancer death rates. 

The specific research objective is twofold: (1) Identify key characteristics that are associated with cancer death rates, and (2) Build a model to predict the cancer death rate in each county, normalized according to population. The dataset we used was aggregated from various U.S. governmental sources, including census.gov, clinicaltrials.gov, and cancer.gov , and we used additional geographic data from the U.S. Department of Agriculture and census.gov. **Figure 1** shows the distribution of cancer death rates across the U.S by state. Through building a regression model and analyzing the predictions of our model, perhaps we can glean some insight into the characteristics of cancer mortality rates in the United States.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.width=5.5, fig.height=2.5, fig.align='center'}
# Plot Target Rate by State
state_grouped <- df %>%
	group_by(state) %>%
	summarise(
	  TARGET_deathRate = mean(TARGET_deathRate),
	  PctPrivateCoverage = mean(PctPrivateCoverage),
	  BirthRate = mean(BirthRate)
	  )

suppressWarnings(plot_usmap(data = state_grouped, values = "TARGET_deathRate") + 
  scale_fill_continuous(low = "white", high = "red",
                name = "Death Rate", label = scales::comma) + 
  theme(legend.position = "right"))
```

**Figure 1**: Distribution of mean per capita (100,000) cancer mortalities

# Data Description

To predict our dependent variable `TARGET_deathRate` (mean per capita cancer mortalities), We categorized our independent variables into seven main categories, listed below (see **Appendix A** for full data dictionary): 

1. Cancer-related Demographics:`avgAnnCount`, `avgDeathsPerYear`, `incidenceRate`, `studyPerCap`.
2. General Demographics: `MedianAge`, `popEst2015`, `MedianAgeFemale`, `BirthRate`.
3. Racial Demographics: `PctWhite`, `PctBlack`, `PctOtherRace`.
4. Education and Employment Demographics: `PctBachDeg18-24`, `PctHS25_Over`, `PctBachDeg25_Over`.
5. Insurance Coverage Demographics: `PctPrivateCoverage`, `PctEmpPrivCoverage`.
6. Income and Household Demographics: `medIncome`, `povertyPercent`, `AvgHouseholdSize`, `PctMarried`.
7. Geographic Features: `Division` and one hot encoded state variables.

# Final Model
```{r, echo=FALSE, results=FALSE}
states_df <- read.csv('Data/geography_cleaned.csv')
bh_formula <- 'TARGET_deathRate ~ incidenceRate + povertyPercent + 
    PercentMarried + PctHS18_24 + PctBachDeg18_24 + PctHS25_Over + 
    PctBachDeg25_Over + PctUnemployed16_Over + PctEmpPrivCoverage + 
    PctWhite + PctBlack + PctOtherRace + PctMarriedHouseholds + 
    BirthRate + Division + state_Missouri + state_Virginia + 
    state_Alaska + state_Arkansas + state_Oklahoma + state_Indiana + 
    state_Alabama + state_Georgia + state_North.Carolina + state_Wyoming + 
    state_Ohio + state_Hawaii + state_Kansas + state_Nevada + 
    state_Connecticut + state_Kentucky +
    Division:incidenceRate +
    Division:povertyPercent +
    Division:PctUnemployed16_Over +
    Division:PctEmpPrivCoverage +
    Division:PctWhite'
bh_formula <- str_replace_all(bh_formula, "[\r\n]", "")
bh_model <- eval(bquote(lm(.(as.formula(bh_formula)), data = states_df)))
summary(bh_model)
```

Our final model ends up regressing on 78 variables. This number includes the variables described in the data description section, dummy variables generated by our state and division levels, and interaction terms. The model's adjusted $R^2$ value is 0.584, which is an improvement from approximately 0.54 in our full data model after EDA, and its root mean squared error is 18.3 (MSE of 334) cancer mortalities (per capita (100,000)).

```{r, echo=FALSE, fig.height=3.5}
par(mfrow = c(2,2), mai=c(0.3, 0.3, 0.3, 0.3))
plot(bh_model)
```

**Figure 2:** Model diagnostics plots of the final model.

The assumptions of linear regression are largely met as well. As seen in **Figure 2**, the residuals show no sign of patterns when plotted against the fitted values indicating that our data is fairly linear. The Normal Q-Q plot is almost linear as well, although there are slight deviations at the ends. This indicates that the model follows the normal distribution fairly well. The scale-location plot shows that the residuals are spread fairly equally along the fitted values which means that our final model has a relatively constant error variance. The residuals vs leverage plot reveals that while there are a few points with high leverage, no points exceed the Cook's distance boundary as demarked by the red dotted line. This leads us to interpret the data as not having any points that are too out of the ordinary.

In **Figure 3**, we display the model's predictive ability in a visual manner. We observe that the model is able to identify major geographic trends, but it does struggle to capture some outliers. However, through manual inspection, we know that the counties in the South and Midwest regions have the largest cancer death rates, so we can be confident that our model would be able to identify the most high risk counties.

```{r, echo=FALSE}
# Load Lat/Lon data
usa <- map_data("usa")
states <- map_data("state")
AllCounty <- map_data("county")

# Make Predictions for each county
states_df$predictedRates <- c(predict(bh_model, states_df))
```

```{r, echo=FALSE}
plot_top_counties <- function(n) {
  # Plot predicted vs actual
  # n: top counties we want to visualize (int)
  county_df <- AllCounty
  plot_list <- list()
  columns <- c("TARGET_deathRate", "predictedRates")
  
  for (i in 1:2) {
    column <- columns[i]
    topN <- states_df[order(-states_df[column]),][1:n, ]
    
    topactual_counties <- tolower(topN$County)
    topactual_states <- tolower(topN$State)
    
    county_df$DeathRate <- ifelse((county_df$subregion %in% topactual_counties) & 
                            (county_df$region %in% topactual_states) , 'High', 'Low')
    
    sub <- paste0("Top ", n, " Counties with highest rates")
    if (column == "TARGET_deathRate") {
      title <- "Actual Death Rates"
    } else {
      title <- "Predicted Death Rates"
    }
    
    p <- ggplot() + geom_polygon( data=states, aes(x=long, y=lat, group=group),
                  color="black", size = 0.5) +
            geom_polygon(data=county_df, aes(x=long, y=lat, 
                  group=group, fill=DeathRate),
                  color="black",  size = 0.3) +
          scale_fill_brewer(palette="Set1") +
          ggtitle(title, subtitle=sub) +
          theme(legend.position = "none")
    plot_list[[i]] <- p
  }
  return(grid.arrange(grobs=plot_list, nrow=1))
}
```

```{r, echo=FALSE, fig.width=10, fig.height=3.5}
plot_top_counties(300)
```

**Figure 3**: Actual death rates vs. predicted death rates

To gain further insight into feature characteristics, we standardized our coefficients to rank their importances (see **Appendix C** for full results). **Table 1** outlines the five features most positively associated with the target death rate, and the five features most negatively associated with it. In gerneal, we notice that the coefficient estimates are quite small, which is likely a byproductive of a large feature space and the complexity of predicting cancer death rates. The East South Central Division is more highly associated with death rates compared to other divisions. This divison includes Kentucky, Tennessee, Mississippi, and Alabama, and this aligns with **Figure 3**. Conversely, we notice that the Middle Atlantic and Mountain Divisions are negatively associated with death rates, which is also confirmed by the previous figure. We also notice that death rates are highly associated with Incidence Rate (mean number of diagnoses) and unemployment rates, which align with reasonable expectations, since unemployed individuals have fewer financial resources to comply with their basic needs.

However, because we performed rigorous variable selection, our coefficient estimates may not truly reflect actual associations. For example, we observe that there is a negative association between death rates and the interaction between unemployment and the Eath South Central Division, despite the general positive association with that division. Overall though, our model makes decent predictions for county-level death rate predictions, and it reasonably learns geographic trends.

| Feature | Coefficient Estimate |
|:---|:---:|
| East South Central Division | 0.35300 |
| Poverty Percent : East South Central Division | 0.28105 |
| Incidence Rate | 0.24171 |
| Percent Unemployment 16 and Over | 0.22097 |
| Incidence Rate : East South Central Division | 0.17943 |
| Middle Atlantic Division | -0.44820 |
| Mountain Division | -0.40165 |
| Percent Unemployment 16 and Over : Mountain Division | -0.35636 |
| Percent Unemployment 16 and Over : East South Central Division | -0.26936 |
| Percent White : West North Central | -0.25461 |

**Table 1**: Largest (magnitude) standardized coefficient estimates from final model

# Discussion and Future Improvements

If we were to widen our project scope, we would like to further develop this model by fitting it to specific types of cancer. In those scenarios, we could analyze common statistically significant variables and quantify their association with the cancer’s death rate for a county.  Ideally, we could also work with government institutions to see to collect more data. For example, if we could aggregate another set of demographic features at the county level, we may be able to extend our associations, and pick up on new patterns and interactions. Since our dataset was based on aggregated data from 2010-2015 estimates, working with future data to forecast county death rates for counties would be serve as an excellent addendum to our project. With the addition of data over time, we would be able to build time series models which would perhaps be more suited at predicting cancer death rates for future time periods.

While our model was built for the purposes of prediction and association, this model can serve as a stepping stone into causal inference. Future studies could be done using some of the coefficients we deemed important as treatment variables and perhaps further investigating these factors in a controlled environment as opposed to the observational data our dataset is comprised of. For example, we could investigate the effect that unemployment rates, healthcare spending, or cancer research spending have on cancer death rate.

# Conclusion 

Our goal with this analysis was to find the best possible model for predicting the cancer death rate of a county given various characteristics of that county. Prediction of cancer death rates is important for several reasons. If a county's actual cancer death rate is significantly different from its predicted cancer death rate, then that county may need to be investigated. This difference between predicted and actual death rate could stem from anything including a drastic change in county characteristics, the rise of a new explanatory variable that has a significant influence on cancer death rates, or perhaps errors when reporting cause of death. No matter the reason, and whether the predicted death rate is higher or lower than the actual death rate, a significant deviation from the prediction is cause for investigation.  In addition, our model can serve as an initial tool to inform government institutions about strong social, economic, and medical associations, and about the need to brainstorm ideas into establishing support systems for regions who have high predicted death rates.

# Additional Work

## Data Cleaning and Exploratory Data Analysis

We started the EDA process by checking to see if there are any columns that contained substantial missing values. We removed columns `PctSomeCol18_24` (2285 N/A), `PctEmployed16_Over` (152 N/A), `PctPrivateCoverageAlone` (609 N/A). We then took out binnedInc as once we changed it into a numeric vector and taking means of every row's lower and upper decile, we decided that it would not be appropriate as it categorizes income into 10 splits and provides similar information to medIncome.

Two important issues that we would need to address in order for our model to yield substantial information would be linearity, in which there must be a linear relationship between the independent and dependent variables, and multicollinearity, where our independent variables are too highly correlated with one another. We have addressed the former by interpreting the model diagnostics during the discussion portion, and we will be dealing with multicollinearity in this section. 

Since we have multiple variables for regression, we would want to detect multicollinearity within our regressors to avoid. Having multicollinearity affects the variance of our model’s prediction, which reduces the quality of interpreting our independent variables. We tackle this issue through two means: construction of a correlation plot (**Figure 4**) and removing variables that yield a relatively high variance inflation factor (VIF). We used a cutoff VIF of 10$^1$to remove 8 features from our dataset: `avgDeathsPerYear`, `popEst2015`, `MedianAgeFemale`, `MedianAgeMale`, `MedianAge`, `PctPrivateCoverage`, `PctPublicCoverage`, and `PctPublicCoverageAlone`. 

```{r, echo=FALSE, results = FALSE}
df2 <- df[,c(1:29)]
```
```{r,echo=FALSE, fig.height = 3.5, fig.width = 5, fig.align = "center"}
p.mat <- cor.mtest(df2)$p

corrplot(cor(df2), type = "upper", order = "hclust", tl.pos = "td", tl.cex = 0.5, method = "color", 
         p.mat = p.mat, sig.level = 0.1, insig = "blank")
```

**Figure 4:** Correlation plot of numeric features.

## Model Selection

Because our model is focused on prediction rather than causal inference, we decided to undergo a rigorous variable selection process. After removing variables deemed too severely multicollinear, we're left with a "full" model consisting of 21 explanatory variables.
```{r, echo=FALSE, results=FALSE}
df <- read.csv('Data/vif_removed_features.csv')
df <- na.omit(df)
df$County <- NULL
df$state <- NULL
df$fips <- NULL
df$Region <- NULL
df
```

```{r, echo=FALSE, results=FALSE}
full_model <- lm(TARGET_deathRate ~ ., data=df)
summary(full_model)
```
The reason we chose to screen our variables with VIF beforehand is that removing explanatory variables that are collinear not only helps with the assumptions of linear regression, but also helps computationally, as we have less variables to search through when searching for the best model. 

### Screening With LASSO

Before performing best subsets regression, we decided to run LASSO on our model in order to get a sense of variable importance in a predictive context.

```{r, echo=FALSE, fig.height = 3, fig.width = 5, fig.align = "center"}
# glmnet uses matrix-vector syntax, not formula syntax
# Create model matrix (variables automatically standardized by glmnet; intercept automatically included)
X <- model.matrix(TARGET_deathRate ~ ., df)[, -1]
y <- df$TARGET_deathRate

# Fit lasso path over lambda.grid
lasso.mod <- glmnet(x = X, y = y, alpha = 1)
#cross validated lasso 
cv.lasso.mod <- cv.glmnet(x = X, y = y, alpha = 1, nfolds = 10)
#plot(cv.lasso.mod)

best.lasso.lam <- cv.lasso.mod$lambda.min

# Plot the lasso path on the lambda scale and add a line for the values at the best lambda
plot(lasso.mod, xvar = "lambda")
lines(c(log(best.lasso.lam), log(best.lasso.lam)), 
      c(-1000, 1000), lty = "dashed", lwd = 3)
```

**Figure 5:** Lasso coefficient trails. The dotted line marks the optimal lambda.

```{r, echo=FALSE, results=FALSE}
# LASSO results
best.lasso.coefs <- predict(lasso.mod, type = 'coefficients', s = best.lasso.lam)
best.lasso.coefs
lasso_model <- lm(TARGET_deathRate ~ ., data=df)
```

Taking a look at the results of LASSO, we see that none of our coefficients have been zeroed out, meaning that we will need to take a look at other variable selection methods if we want to shrink our model. As a result, we explore a different method of model shrinkage: best subsets regression.

### Best Subsets Regression

Best subsets regression exhaustively searches every combination of variables for every possible model size and selects the best models for each model size according to different criteria. The criteria we considered were Adjusted $R^2$, Mallow's Cp, and BIC. We chose these three criteria since they're supported by the R function regsubsets, and we wanted to use the same library for the sake of consistency in model selection.
```{r, echo=FALSE, results=FALSE}
regfit.full = regsubsets(TARGET_deathRate ~ ., method = "exhaustive", data = df, nvmax = 30)
satreg.summary = summary(regfit.full)

# Dataframe with best number of coefficients for each model
data.frame(
  Adj.R2 = which.max(satreg.summary$adjr2),
  CP = which.min(satreg.summary$cp),
  BIC = which.min(satreg.summary$bic)
)
```
```{r, echo=FALSE}
entries <- c("23", "21", "16")
tbl<-matrix(entries,ncol=3,byrow=TRUE)
rownames(tbl)<-c("Number of Variables")
colnames(tbl)<-c("Adjusted R^2", "Mallow's Cp", "BIC")
tbl1 <- as.table(tbl)
tbl %>%
  kbl() %>%
  kable_classic_2(full_width = F)
```

**Table 2:** The number of variables in the "best" model as chosen by various criteria. Note that the number of variables has increased due to dummy variables being added to the model.

As seen in **Table 2**, Adjusted $R^2$ as our criterion resulted in the largest model, while BIC as our criterion resulted in the smallest model. Taking a closer look at the actual models that were selected, we see that some of our dummy variables for our only categorical variable, region, ended up being dropped by best subset regression. Because it's not possible to write a formula that drops some of these dummy variables as well as the fact that the majority of dummy variables were kept for all 3 models, we chose to keep Division in all 3 of our models even if some of the dummy variables ended being dropped. This isn't too consequential as in the Adjusted R^2 model and the Mallow's Cp Model, only the dummy variable associated with the South Atlantic division is dropped, while in the BIC model, only the dummy variables associated with the South Atlantic division and New England division are dropped.
```{r, echo=FALSE, results=FALSE}
# Adjusted R^2
satreg.summary$which[23,]
adjusted_r2_model <- lm(TARGET_deathRate ~ . - medIncome - studyPerCap - PctNoHS18_24 - PctAsian, data=df)

# Mallow's Cp
satreg.summary$which[21,]
cp_model <- lm(TARGET_deathRate ~ . - medIncome - avgAnnCount - studyPerCap - AvgHouseholdSize - PctNoHS18_24 - PctAsian, data=df)
# BIC
satreg.summary$which[16,]
bic_model <- lm(TARGET_deathRate ~ . - avgAnnCount - medIncome - studyPerCap - AvgHouseholdSize - PercentMarried - PctNoHS18_24 - PctBachDeg18_24 - PctEmpPrivCoverage - PctAsian - BirthRate, data=df)
```

### Cross Validation

After creating our models (2 distinct ones in this case), it's clear the the criteria don't agree on which model is the best. In order to assess the performance of our models, we need to evaluate the predictive ability of our models on data they have never seen before. Rather than using a train-test split of our data, we decided to use cross validation since cross validation tends to smooth out noise or randomness, and also provides more precision while reducing bias as we have more data for fitting the models. Leave-one-out CV is too computationally expensive due to the large number of rows, so we went with k-fold CV instead with a fold size of 10. We also computed the MSE from CV for the full model as well as the LASSO model to serve as comparisons.

```{r, fig.show='hide', results=FALSE, echo=FALSE}
# Calculating MSEs for each model
full.cv <- cv.lm(data=df, full_model, m=10)
full.mse <- attr(full.cv, "ms")

lasso.cv <- cv.lm(data=df, lasso_model, m=10)
lasso.mse <- attr(lasso.cv, "ms")

adjr2.cv <- cv.lm(data=df, adjusted_r2_model, m=10)
adjr2.mse <- attr(adjr2.cv, "ms")

cp.cv <- cv.lm(data=df, cp_model, m=10)
cp.mse <- attr(cp.cv, "ms")

bic.cv <- cv.lm(data=df, bic_model, m=10)
bic.mse <- attr(bic.cv, "ms")
```
```{r, results=FALSE, echo=FALSE}
# CV MSE
full.mse
lasso.mse
adjr2.mse
cp.mse
bic.mse
```

```{r, echo=FALSE}
entries <- c("359", "359", "358", "358", "359")
tbl<-matrix(entries,ncol=5,byrow=TRUE)
rownames(tbl)<-c("MSE")
colnames(tbl)<-c("Full Model", "LASSO Model", "Adjusted R^2 Model", "Mallow's Cp Model", "BIC Model")
tbl2 <- as.table(tbl)
tbl %>%
  kbl() %>%
  kable_classic_2(full_width = F)
```

**Table 3:** The MSE from k-fold CV of our various models. Note that the MSE of our full model and LASSO model are the same since the two models are the same (albeit it's definitely possible for two different models to have the same MSE).

As seen in **Table 3**, the models with the lowest MSE ended up being our Mallow's Cp and Adjuted $R^2$ models. Because the Mallow's Cp model is smaller (2 fewer features), we'll choose that model as our "final" model for this step.

### Model Diagnostics

```{r, echo=FALSE, results=FALSE}
summary(cp_model)
```

```{r, echo=FALSE, fig.height=4}
# Diagnostic Plots
par(mfrow = c(2,2), mai=c(0.3, 0.3, 0.3, 0.3))
plot(cp_model)
```

**Figure 6:** Diagnostic plots of the chosen model.

We notice an outlier in our residual plots in **Figure 6** that reveal a point with a somewhat high leverage. After investgating the possibility of an encoding error, we discovered that this point belonged to Union County, Florida which is known to have a disproportionately high cancer death rate compared to the rest of the United States, so we left that data point in. Something that was concerning during EDA was that a few of our explanatory variables didn't have normal distributions. When we applied a Box-Cox transformation, our model performance actually slightly decreased with a lower $R^2$ in our model as well as a higher MSE during cross validation. As a result, we decided to not pursue a transformation of our variables prior to variable selection. After variable selection, applying a Box-Tidwell transformation was considered, but due to powers being pushed to infinity and being unable to diagnose this issue as Box-Tidwell wasn't covered in class, we decided to not continue pursuing this particular transformation. **Figure 6** reveals that the assumptions of linear regression are mostly followed anyways, so a transformation wouldn't necessarily create a huge improvement.

### Adding States to the Model

While we have region as one of the variables in our model, it's possible that certain states may go against the trend of the region. As a result, we will consider adding states as variables to our model. Doing so will allow the coefficient of a state to "counteract" the coefficient of its region in the event that a state is significantly different than its region. In order to decide which states to add to our model, we will use forward selection using AIC and BIC as our criteria. We chose to do forward selection rather than best subsets regression here due to the large number of additional columns we have added via one hot encoding the state variable. We chose AIC and BIC as our criteria since they're supported by the step function and we want to use the same library for the sake of consistency during model selection.

```{r, echo=FALSE, results=FALSE}
states_df <- read.csv('Data/geography_cleaned.csv')
states_df <- na.omit(states_df)
states_df$County <- NULL
states_df$fips <- NULL
states_df$Region <- NULL
states_df$avgAnnCount <- NULL
states_df$studyPerCap <- NULL
states_df$AvgHouseholdSize <- NULL
states_df$PctNoHS18_24 <- NULL
states_df$PctAsian <- NULL
states_df$medIncome <- NULL
states_df$State <- NULL #
states_df
```
```{r, echo=FALSE}
final_model <- lm(TARGET_deathRate ~ incidenceRate + 
    povertyPercent + PercentMarried + PctHS18_24 + 
    PctBachDeg18_24 + PctHS25_Over + PctBachDeg25_Over +
    PctUnemployed16_Over + PctEmpPrivCoverage + 
    PctWhite + PctBlack + PctOtherRace + PctMarriedHouseholds + 
    BirthRate + Division, data=states_df)
```


```{r, echo=FALSE}
# Forward Selection with AIC
biggest <- formula(lm(TARGET_deathRate ~ ., data = states_df))
fwd.aic <- step(final_model, direction = "forward", scope = biggest, trace=0)

# Forward Selection with BIC
fwd.bic <- step(final_model, direction = "forward", scope = biggest, k=log(nrow(states_df)), trace=0)
```
```{r, echo=FALSE, results=FALSE}
fwd.aic
fwd.bic
```
```{r, fig.show='hide', results=FALSE, echo=FALSE}
# Calculating MSEs for each model
fwd.aic.cv <- cv.lm(data=states_df, fwd.aic, m=10)
fwd.aic.mse <- attr(fwd.aic.cv, "ms")

fwd.bic.cv <- cv.lm(data=states_df, fwd.bic, m=10)
fwd.bic.mse <- attr(fwd.bic.cv, "ms")
```
```{r, echo=FALSE, results=FALSE}
fwd.aic.mse
fwd.bic.mse
```

```{r, echo=FALSE, results=FALSE}
entries <- c("16", "7")
tbl<-matrix(entries,ncol=2,byrow=TRUE)
rownames(tbl)<-c("States Added")
colnames(tbl)<-c("AIC", "BIC")
tbl3 <- as.table(tbl)
tbl %>%
  kbl() %>%
  kable_classic_2(full_width = F)
```
The results of our forward selection reveal that adding states does in fact add precision to our model - AIC adds 16 states to our model and BIC adds 7 states to our model. AIC adds significantly more variables than BIC, though that's not surprising considering that BIC penalizes model complexity more heavily. The states chosen by both BIC and AIC tend to be in the Southern and Midwest regions of the United States, perhaps revealing that these regions contain many outlier states. In order to determine which model fits the data better, we again ran k-fold cross validation (with a fold size of 10) on these two models and because the AIC model had a lower MSE, we chose the AIC model as our "final" model for this stage of the model selection process. Our model now has 38 total variables (counting the dummy variables for Division as separate variables) with the addition of the 16 state variables.

### Interaction Selection

Because our model selection process yielded a design matrix with 38 features, it was computationally infeasible to assess the presence of $2^38$ possible interactions. We hypothesized that the most informative, and likely most interpretable, interactions occur between a continuous value and a certain division of the U.S. Divisions are a finer categorization of region, broken down in **Appendix B**:

We acknowledge that there may be some state-level interactions as well, but again we decided it was infeasible to test all of these interactions. However, the forward selection above should identify "outlier" states, so the combination of division-level interactions and state-specific coefficients should capture state-level characteristics in our model. **Figure 7** displays two interactions that we assessed.
```{r, echo=FALSE}
plot_interactions <- function(features, df) {
  # Function plots all features from given data frame and 
  # given category to test for interactions
  plot_list <- list()
  for (i in 1:length(features)) {
    sub_df <- df %>%
      dplyr::select(features[[i]], "TARGET_deathRate", "Division")
    title <- paste("Interaction between Division and", colnames(sub_df)[1])
    p <- ggplot(sub_df, aes_string(x=colnames(sub_df)[1], y = "TARGET_deathRate", 
                                   colour="Division")) + 
                    geom_point(size = 0.7) + 
                    geom_smooth(method='lm', formula= y~x, se=FALSE) +
                    ggtitle(title) +
                    labs(title = NULL)
    plot_list[[i]] <- p
  }
  num_rows = ceiling (length(plot_list) / 2)
  return(grid.arrange(grobs=plot_list, nrow=num_rows))
}
```

```{r, echo=FALSE, fig.width=8, fig.height=3}
features <- c('PctUnemployed16_Over', 'PctWhite')
plot_interactions(features, states_df)
```

**Figure 7:** Division-level interactions.

After plotting all division-level interactions, we determined that there was visual evidence of 11 possible interactions: To ultimately decide whether or not these interactions improved our model, we used F-tests comparing the full model with all interactions to the model with each interaction removed. Because we conducted 11 tests, we applied two different correction factors to control the family wise error rate at $\alpha=0.05$: Bonferroni and Benjamini-Hochberg. We then removed any interactions that were not significant at the corrected significance level.

The two methods yielded different results for significant interactions, so we again used 10-fold cross validation to determine which correction method produced a better model. Benjamini-Hochberg yielded a lower cross-validated MSE of 334, which was also the best MSE amongst all previous model iterations. The selected interactions are listed below:

1. Division:incidenceRate
2. Division:povertyPercent
3. Division:PctUnemployed16_Over
4. Division:PctEmpPrivCoverage
5. Division:PctWhite

Because this model with interactions produced the lowests MSE, we established this as our final model.

```{r, echo=FALSE}
full_formula <- 'TARGET_deathRate ~ incidenceRate + povertyPercent + 
    PercentMarried + PctHS18_24 + PctBachDeg18_24 + PctHS25_Over + 
    PctBachDeg25_Over + PctUnemployed16_Over + PctEmpPrivCoverage + 
    PctWhite + PctBlack + PctOtherRace + PctMarriedHouseholds + 
    BirthRate + Division + state_Missouri + state_Virginia + 
    state_Alaska + state_Arkansas + state_Oklahoma + state_Indiana + 
    state_Alabama + state_Georgia + state_North.Carolina + state_Wyoming + 
    state_Ohio + state_Hawaii + state_Kansas + state_Nevada + 
    state_Connecticut + state_Kentucky +
    Division:incidenceRate +
    Division:povertyPercent +
    Division:PercentMarried +
    Division:PctBachDeg18_24 +
    Division:PctBachDeg25_Over +
    Division:PctUnemployed16_Over +
    Division:PctEmpPrivCoverage +
    Division:PctWhite +
    Division:PctOtherRace +
    Division:PctMarriedHouseholds +
    Division:BirthRate'
full_formula <- str_replace_all(full_formula, "[\r\n]", "")
full_model <- eval(bquote(lm(.(as.formula(full_formula)), data = states_df)))

interactions <- c('Division:incidenceRate', 'Division:povertyPercent',
                  'Division:PercentMarried', 'Division:PctBachDeg18_24',
                  'Division:PctBachDeg25_Over', 'Division:PctUnemployed16_Over',
                  'Division:PctEmpPrivCoverage', 'Division:PctWhite',
                  'Division:PctOtherRace', 'Division:PctMarriedHouseholds',
                  'Division:BirthRate')

# Run F-test comparing full model to model without one interaction
# Store p-values in a list
p_vals <- list()
for (i in 1:length(interactions)) {
  sub_pattern <- paste("[+]\\s+", interactions[[i]])
  sub_formula <- sub(sub_pattern, "", full_formula)
  reduced_model <- eval(bquote(lm(.(as.formula(sub_formula)), data = states_df)))
  p_val <- anova(full_model, reduced_model)$"Pr(>F)"[2]
  p_vals[[i]] <- p_val
}

# print('BH Interactions')
# print(interactions[p.adjust(p_vals, method="BH", n=length(p_vals)) < 0.05])
# print('Bonferroni Interactions')
# print(interactions[p.adjust(p_vals, method="bonferroni", n=length(p_vals)) < 0.05])
```

# References

1. https://www.businessinsider.com/union-county-is-least-healthy-in-us-2017-10
\newline
2. https://www.cancer.org/latest-news/understanding-cancer-death-rates.html
\newline
3. https://www.cancer.org/research/cancer-facts-statistics/all-cancer-facts-figures/cancer-facts-figures-2020.html
\newline
4. https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf
\newline
5. https://www.data.world/nrippner/ols-regression-challenge
\newline
6. Fox, John. Applied Regression Analysis and Generalized Linear Models. Sage, 2016. 
\newline
7. Gordon, Rachel A. 2015. Regression Analysis for the Social Sciences. 
New York and London: Routledge.
\newline
8. https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697

\newpage

# Appendix

## Appendix A: Full Data Dictionary

- `TARGET_deathRate`: Dependent variable. Mean per capita (100,000) cancer mortalities(a)
- `avgAnnCount`: Mean number of reported cases of cancer diagnosed annually(a)
- `avgDeathsPerYear`: Mean number of reported mortalities due to cancer(a)
- `incidenceRate`: Mean per capita (100,000) cancer diagoses(a)
- `medianIncome`: Median income per county (b)
- `popEst2015`: Population of county (b)
- `povertyPercent`: Percent of populace in poverty (b)
- `studyPerCap`: Per capita number of cancer-related clinical trials per county (a)
- `binnedInc`: Median income per capita binned by decile (b)
- `MedianAge`: Median age of county residents (b)
- `MedianAgeMale`: Median age of male county residents (b)
- `MedianAgeFemale`: Median age of female county residents (b)
- `Geography`: County name (b)
- `AvgHouseholdSize`: Mean household size of county (b)
- `PercentMarried`: Percent of county residents who are married (b)
- `PctNoHS18_24`: Percent of county residents ages 18-24 highest education attained: less than high school (b)
- `PctHS18_24`: Percent of county residents ages 18-24 highest education attained: high school diploma (b)
- `PctSomeCol18_24`: Percent of county residents ages 18-24 highest education attained: some college (b)
- `PctBachDeg18_24`: Percent of county residents ages 18-24 highest education attained: bachelor's degree (b)
- `PctHS25_Over`: Percent of county residents ages 25 and over highest education attained: high school diploma (b)
- `PctBachDeg25_Over`: Percent of county residents ages 25 and over highest education attained: bachelor's degree (b)
- `PctEmployed16_Over`: Percent of county residents ages 16 and over employed (b)
- `PctUnemployed16_Over`: Percent of county residents ages 16 and over unemployed (b)
- `PctPrivateCoverage`: Percent of county residents with private health coverage (b)
- `PctPrivateCoverageAlone`: Percent of county residents with private health coverage alone (no public assistance) (b)
- `PctEmpPrivCoverage`: Percent of county residents with employee-provided private health coverage (b)
- `PctPublicCoverage`: Percent of county residents with government-provided health coverage (b)
- `PctPubliceCoverageAlone`: Percent of county residents with government-provided health coverage alone (b)
- `PctWhite`: Percent of county residents who identify as White (b)
- `PctBlack`: Percent of county residents who identify as Black (b)
- `PctAsian`: Percent of county residents who identify as Asian (b)
- `PctOtherRace`: Percent of county residents who identify in a category which is not White, Black, or Asian (b)
- `PctMarriedHouseholds`: Percent of married households (b)
- `BirthRate`: Number of live births relative to number of women in county (b)

- (a): years 2010-2016
- (b): 2013 Census Estimates

## Appendix B: Descriptions of geographic division

| Division | Region| Number of States |
|:---:|:---:|:---:|
| New England | Northeast | 6 |
| Middle Atlantic | Northeast | 3 |
| East North Central | Midwest | 5 |
| West North Central | Midwest | 7 |
| South Atlantic | South | 9 |
| East South Central | South | 4 |
| West South Central | South | 4 |
| Mountain | West | 8 |
| Pacific | West | 5 |

## Appendix C: All regression coefficient estimates

```{r, fig.width=7, fig.height=10}
plot_model(bh_model, sort.est = TRUE, type="std")
```

## Appendix D: Code

```{r, eval=FALSE}
### Data cleaning
cancer <- read.csv("Data/cancer_reg.csv")
fips_codes <- read.csv("Data/FIPS_codes.csv")
state_abbr <- read.csv("Data/State_Abbreviation_Mapping.csv") 
regions <- read.csv("Data/regions.csv")

# Cleaned N/A columns
cancer <- subset(cancer, select=-c(PctSomeCol18_24, PctEmployed16_Over, 
                                   PctPrivateCoverageAlone, binnedInc)) 

# Clean coding error, applied log-transformation of 
# PctBachDeg25_Over after plot inspection. 

cancer[cancer$MedianAge > 100,]$MedianAge = 40.8
cancer[cancer$AvgHouseholdSize < 1,]$AvgHouseholdSize = 1

#Joining Datasets, columns w/ Geographic features. 

County <- sub(",.*$", "", cancer$Geography)
State <- sub("^.*,\\s*", "", cancer$Geography)

empty_subs = c(" County", " Parish", " City and Borough", 
               " Municipality", " Borough", " Census Area")
for (sub_string in empty_subs) {
  County <- sub(sub_string, "", County) 
}

County <- sub("city", "City", County) 
County <- sub("St ", "St. ", County) 

cancer$County<- County
cancer$State <- State
cancer <- subset(cancer, select = -c(Geography)) # Redundant
cancer<- cancer %>% 
  rename(
    state = State
    )

fips_codes$County <- sub("St ", "St. ", fips_codes$County) 
fips <- merge(fips_codes, state_abbr[, c('State', 'Postal.Abbreviation')], 
      by.x='State', by.y='Postal.Abbreviation', all.x=TRUE)
fips <- fips %>% 
  rename(
    State.Abbreviation = State,
    state = State.y
    )
cancer <- left_join(cancer, fips, by=c('County', 'state'))
cancer <- cancer %>% 
  rename(
    fips = FIPS
    )

df <- left_join(cancer, regions, by=c('state'))
df <- subset(df, select = -c(State.Code, State.Abbreviation) )
```

```{r, eval=FALSE, warning=FALSE, message=FALSE, fig.width=6, fig.height=3}
# Plot Target Rate by State
state_grouped <- df %>%
	group_by(state) %>%
	summarise(
	  TARGET_deathRate = mean(TARGET_deathRate),
	  PctPrivateCoverage = mean(PctPrivateCoverage),
	  BirthRate = mean(BirthRate)
	  )

suppressWarnings(plot_usmap(data = state_grouped, values = "TARGET_deathRate") + 
  scale_fill_continuous(low = "white", high = "red",
                name = "Death Rate", label = scales::comma) + 
  theme(legend.position = "right"))
```

```{r, eval=FALSE, results=FALSE}
# Final Model
states_df <- read.csv('Data/geography_cleaned.csv')
bh_formula <- 'TARGET_deathRate ~ incidenceRate + povertyPercent + 
    PercentMarried + PctHS18_24 + PctBachDeg18_24 + PctHS25_Over + 
    PctBachDeg25_Over + PctUnemployed16_Over + PctEmpPrivCoverage + 
    PctWhite + PctBlack + PctOtherRace + PctMarriedHouseholds + 
    BirthRate + Division + state_Missouri + state_Virginia + 
    state_Alaska + state_Arkansas + state_Oklahoma + state_Indiana + 
    state_Alabama + state_Georgia + state_North.Carolina + state_Wyoming + 
    state_Ohio + state_Hawaii + state_Kansas + state_Nevada + 
    state_Connecticut + state_Kentucky +
    Division:incidenceRate +
    Division:povertyPercent +
    Division:PctUnemployed16_Over +
    Division:PctEmpPrivCoverage +
    Division:PctWhite'
bh_formula <- str_replace_all(bh_formula, "[\r\n]", "")
bh_model <- eval(bquote(lm(.(as.formula(bh_formula)), data = states_df)))
summary(bh_model)
```

Our final model ends up regressing on 78 variables. This number includes the variables described in the data description section, dummy variables generated by our state and division levels, and interaction terms. The model's adjusted $R^2$ value is 0.584 which is an improvement from approximately 0.54 in our full data model after EDA.

```{r, eval=FALSE, fig.height=4}
# Final Model Diagnostics
par(mfrow = c(2,2), mai=c(0.3, 0.3, 0.3, 0.3))
plot(bh_model)
```

```{r, eval=FALSE}
# Load Lat/Lon data
usa <- map_data("usa")
states <- map_data("state")
AllCounty <- map_data("county")

# Make Predictions for each county
states_df$predictedRates <- c(predict(bh_model, states_df))
```

```{r, eval=FALSE}
## Plot predicted vs actual
plot_top_counties <- function(n) {
  # Plot predicted vs actual
  # n: top counties we want to visualize (int)
  county_df <- AllCounty
  plot_list <- list()
  columns <- c("TARGET_deathRate", "predictedRates")
  
  for (i in 1:2) {
    column <- columns[i]
    topN <- states_df[order(-states_df[column]),][1:n, ]
    
    topactual_counties <- tolower(topN$County)
    topactual_states <- tolower(topN$State)
    
    county_df$DeathRate <- ifelse((county_df$subregion %in% topactual_counties) & 
                            (county_df$region %in% topactual_states) , 'High', 'Low')
    
    sub <- paste0("Top ", n, " Counties with highest rates")
    if (column == "TARGET_deathRate") {
      title <- "Actual Death Rates"
    } else {
      title <- "Predicted Death Rates"
    }
    
    p <- ggplot() + geom_polygon( data=states, aes(x=long, y=lat, group=group),
                  color="black", size = 0.5) +
            geom_polygon(data=county_df, aes(x=long, y=lat, 
                  group=group, fill=DeathRate),
                  color="black",  size = 0.3) +
          scale_fill_brewer(palette="Set1") +
          ggtitle(title, subtitle=sub) +
          theme(legend.position = "none")
    plot_list[[i]] <- p
  }
  return(grid.arrange(grobs=plot_list, nrow=1))
}

plot_top_counties(300)
```

```{r,eval=FALSE, fig.height = 3.5, fig.width = 5, fig.align = "center"}
# Correlation Matrix
df2 <- df[,c(1:29)]
p.mat <- cor.mtest(df2)$p

corrplot(cor(df2), type = "upper", order = "hclust", tl.pos = "td", tl.cex = 0.5, method = "color", 
         p.mat = p.mat, sig.level = 0.1, insig = "blank")
```

```{r, eval=FALSE, results=FALSE}
# Initial Model Selection
df <- read.csv('Data/vif_removed_features.csv')
df <- na.omit(df)
df$County <- NULL
df$state <- NULL
df$fips <- NULL
df$Region <- NULL

full_model <- lm(TARGET_deathRate ~ ., data=df)
summary(full_model)
```

```{r, eval=FALSE, fig.height = 3, fig.width = 5, fig.align = "center"}
### LASSO screening

# glmnet uses matrix-vector syntax, not formula syntax
# Create model matrix (variables automatically standardized by glmnet; 
#intercept automatically included)
X <- model.matrix(TARGET_deathRate ~ ., df)[, -1]
y <- df$TARGET_deathRate

# Fit lasso path over lambda.grid
lasso.mod <- glmnet(x = X, y = y, alpha = 1)
#cross validated lasso 
cv.lasso.mod <- cv.glmnet(x = X, y = y, alpha = 1, nfolds = 10)
#plot(cv.lasso.mod)

best.lasso.lam <- cv.lasso.mod$lambda.min

# Plot the lasso path on the lambda scale and add a line for the values at the best lambda
plot(lasso.mod, xvar = "lambda")
lines(c(log(best.lasso.lam), log(best.lasso.lam)), 
      c(-1000, 1000), lty = "dashed", lwd = 3)

# LASSO results
best.lasso.coefs <- predict(lasso.mod, type = 'coefficients', s = best.lasso.lam)
best.lasso.coefs
lasso_model <- lm(TARGET_deathRate ~ ., data=df)
```

```{r, eval=FALSE, results=FALSE}
### Regsubsets Results

regfit.full = regsubsets(TARGET_deathRate ~ ., method = "exhaustive", data = df, nvmax = 30)
satreg.summary = summary(regfit.full)

# Dataframe with best number of coefficients for each model
data.frame(
  Adj.R2 = which.max(satreg.summary$adjr2),
  CP = which.min(satreg.summary$cp),
  BIC = which.min(satreg.summary$bic)
)

entries <- c("23", "21", "16")
tbl<-matrix(entries,ncol=3,byrow=TRUE)
rownames(tbl)<-c("Number of Variables")
colnames(tbl)<-c("Adjusted R^2", "Mallow's Cp", "BIC")
tbl1 <- as.table(tbl)
tbl %>%
  kbl() %>%
  kable_classic_2(full_width = F)

# Adjusted R^2
satreg.summary$which[23,]
adjusted_r2_model <- lm(TARGET_deathRate ~ . - medIncome - studyPerCap - 
                          PctNoHS18_24 - PctAsian, data=df)

# Mallow's Cp
satreg.summary$which[21,]
cp_model <- lm(TARGET_deathRate ~ . - medIncome - avgAnnCount - studyPerCap - 
                 AvgHouseholdSize - PctNoHS18_24 - PctAsian, data=df)
# BIC
satreg.summary$which[16,]
bic_model <- lm(TARGET_deathRate ~ . - avgAnnCount - medIncome - studyPerCap - 
                  AvgHouseholdSize - PercentMarried - PctNoHS18_24 - 
                  PctBachDeg18_24 - PctEmpPrivCoverage - PctAsian - BirthRate, data=df)
```

```{r, eval=FALSE, fig.show='hide', results=FALSE}
# Calculating MSEs for each model
full.cv <- cv.lm(data=df, full_model, m=10)
full.mse <- attr(full.cv, "ms")

lasso.cv <- cv.lm(data=df, lasso_model, m=10)
lasso.mse <- attr(lasso.cv, "ms")

adjr2.cv <- cv.lm(data=df, adjusted_r2_model, m=10)
adjr2.mse <- attr(adjr2.cv, "ms")

cp.cv <- cv.lm(data=df, cp_model, m=10)
cp.mse <- attr(cp.cv, "ms")

bic.cv <- cv.lm(data=df, bic_model, m=10)
bic.mse <- attr(bic.cv, "ms")

# CV MSE
full.mse
lasso.mse
adjr2.mse
cp.mse
bic.mse

entries <- c("359", "359", "358", "358", "359")
tbl<-matrix(entries,ncol=5,byrow=TRUE)
rownames(tbl)<-c("MSE")
colnames(tbl)<-c("Full Model", "LASSO Model", "Adjusted R^2 Model", 
                 "Mallow's Cp Model", "BIC Model")
tbl2 <- as.table(tbl)
tbl %>%
  kbl() %>%
  kable_classic_2(full_width = F)
```

```{r, eval=FALSE, results=FALSE}
### Regsubsets model diagnostics

summary(cp_model)
# Diagnostic Plots
par(mfrow = c(2,2), mai=c(0.3, 0.3, 0.3, 0.3))
plot(cp_model)
```

```{r, eval=FALSE, results=FALSE}
### Adding States to model
states_df <- read.csv('Data/geography_cleaned.csv')
states_df <- na.omit(states_df)
states_df$County <- NULL
states_df$fips <- NULL
states_df$Region <- NULL
states_df$avgAnnCount <- NULL
states_df$studyPerCap <- NULL
states_df$AvgHouseholdSize <- NULL
states_df$PctNoHS18_24 <- NULL
states_df$PctAsian <- NULL
states_df$medIncome <- NULL
states_df$State <- NULL #
states_df

final_model <- lm(TARGET_deathRate ~ incidenceRate + 
    povertyPercent + PercentMarried + PctHS18_24 + 
    PctBachDeg18_24 + PctHS25_Over + PctBachDeg25_Over +
    PctUnemployed16_Over + PctEmpPrivCoverage + 
    PctWhite + PctBlack + PctOtherRace + PctMarriedHouseholds + 
    BirthRate + Division, data=states_df)
```

```{r, eval=FALSE}
### Forward Selection Results

# Forward Selection with AIC
biggest <- formula(lm(TARGET_deathRate ~ ., data = states_df))
fwd.aic <- step(final_model, direction = "forward", scope = biggest, trace=0)

# Forward Selection with BIC
fwd.bic <- step(final_model, direction = "forward", scope = biggest, k=log(nrow(states_df)), trace=0)

fwd.aic
fwd.bic 

# Calculating MSEs for each model
fwd.aic.cv <- cv.lm(data=states_df, fwd.aic, m=10)
fwd.aic.mse <- attr(fwd.aic.cv, "ms")

fwd.bic.cv <- cv.lm(data=states_df, fwd.bic, m=10)
fwd.bic.mse <- attr(fwd.bic.cv, "ms")

fwd.aic.mse
fwd.bic.mse

entries <- c("16", "7")
tbl<-matrix(entries,ncol=2,byrow=TRUE)
rownames(tbl)<-c("States Added")
colnames(tbl)<-c("AIC", "BIC")
tbl3 <- as.table(tbl)
tbl %>%
  kbl() %>%
  kable_classic_2(full_width = F)
```

```{r, eval=FALSE}
### Plot Interactions

plot_interactions <- function(features, df) {
  # Function plots all features from given data frame and 
  # given category to test for interactions
  plot_list <- list()
  for (i in 1:length(features)) {
    sub_df <- df %>%
      dplyr::select(features[[i]], "TARGET_deathRate", "Division")
    title <- paste("Interaction between Division and", colnames(sub_df)[1])
    p <- ggplot(sub_df, aes_string(x=colnames(sub_df)[1], y = "TARGET_deathRate", 
                                   colour="Division")) + 
                    geom_point(size = 0.7) + 
                    geom_smooth(method='lm', formula= y~x, se=FALSE) +
                    ggtitle(title) +
                    labs(title = NULL)
    plot_list[[i]] <- p
  }
  num_rows = ceiling (length(plot_list) / 2)
  return(grid.arrange(grobs=plot_list, nrow=num_rows))
}

features <- c('PctUnemployed16_Over', 'PctWhite')
plot_interactions(features, states_df)
```

```{r, eval=FALSE}
### Interaction Selection
full_formula <- 'TARGET_deathRate ~ incidenceRate + povertyPercent + 
    PercentMarried + PctHS18_24 + PctBachDeg18_24 + PctHS25_Over + 
    PctBachDeg25_Over + PctUnemployed16_Over + PctEmpPrivCoverage + 
    PctWhite + PctBlack + PctOtherRace + PctMarriedHouseholds + 
    BirthRate + Division + state_Missouri + state_Virginia + 
    state_Alaska + state_Arkansas + state_Oklahoma + state_Indiana + 
    state_Alabama + state_Georgia + state_North.Carolina + state_Wyoming + 
    state_Ohio + state_Hawaii + state_Kansas + state_Nevada + 
    state_Connecticut + state_Kentucky +
    Division:incidenceRate +
    Division:povertyPercent +
    Division:PercentMarried +
    Division:PctBachDeg18_24 +
    Division:PctBachDeg25_Over +
    Division:PctUnemployed16_Over +
    Division:PctEmpPrivCoverage +
    Division:PctWhite +
    Division:PctOtherRace +
    Division:PctMarriedHouseholds +
    Division:BirthRate'
full_formula <- str_replace_all(full_formula, "[\r\n]", "")
full_model <- eval(bquote(lm(.(as.formula(full_formula)), data = states_df)))

interactions <- c('Division:incidenceRate', 'Division:povertyPercent',
                  'Division:PercentMarried', 'Division:PctBachDeg18_24',
                  'Division:PctBachDeg25_Over', 'Division:PctUnemployed16_Over',
                  'Division:PctEmpPrivCoverage', 'Division:PctWhite',
                  'Division:PctOtherRace', 'Division:PctMarriedHouseholds',
                  'Division:BirthRate')

# Run F-test comparing full model to model without one interaction
# Store p-values in a list
p_vals <- list()
for (i in 1:length(interactions)) {
  sub_pattern <- paste("[+]\\s+", interactions[[i]])
  sub_formula <- sub(sub_pattern, "", full_formula)
  reduced_model <- eval(bquote(lm(.(as.formula(sub_formula)), data = states_df)))
  p_val <- anova(full_model, reduced_model)$"Pr(>F)"[2]
  p_vals[[i]] <- p_val
}

# print('BH Interactions')
# print(interactions[p.adjust(p_vals, method="BH", n=length(p_vals)) < 0.05])
# print('Bonferroni Interactions')
# print(interactions[p.adjust(p_vals, method="bonferroni", n=length(p_vals)) < 0.05])
```